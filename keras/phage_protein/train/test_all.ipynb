{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import phage_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#d = {'model': [], 'class': [],'precision':[],'recall':[],'f1-score':[]}\n",
    "d = {'model': [], 'class': [],'score_type':[],'value':[]}\n",
    "df = pd.DataFrame(data=d)\n",
    "F = open('all_models_table.txt','w') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved matrices\n",
    "import pickle\n",
    "train_X_total=pickle.load(open( os.path.join(phage_init.data_dir,\"train_x.p\"), \"rb\" ) )\n",
    "test_X_total=pickle.load(open( os.path.join(phage_init.data_dir,\"test_x.p\"), \"rb\" ) )\n",
    "train_Y=pickle.load(open( os.path.join(phage_init.data_dir,\"train_y.p\"), \"rb\" ) )\n",
    "test_Y=pickle.load(open( os.path.join(phage_init.data_dir,\"test_y.p\"), \"rb\" ) )\n",
    "mean_total=pickle.load(open( os.path.join(phage_init.data_dir,\"mean.p\"), \"rb\" ) )\n",
    "std_total=pickle.load(open( os.path.join(phage_init.data_dir,\"std.p\"), \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_df(df,test_Y_index, test_Y_predicted,model_name):\n",
    "    labels_names=[\"Major capsid\",\"Minor capsid\",\"Baseplate\",\"Major tail\",\"Minor tail\",\"Portal\",\"Tail fiber\",\n",
    "             \"Tail shaft\",\"Collar\",\"Head-Tail joining\"]\n",
    "    labels_dataframe=[\"Major capsid\",\"Minor capsid\",\"Baseplate\",\"Major tail\",\"Minor tail\",\"Portal\",\"Tail fiber\",\n",
    "                 \"Tail shaft\",\"Collar\",\"Head-Tail joining\",\"weighted avg\"]\n",
    "    for label in labels_dataframe:\n",
    "        report=classification_report(test_Y_index, test_Y_predicted, target_names=labels_names,output_dict=True )\n",
    "        #data_row=[report[label][i] for i in ['precision','recall',\"f1-score\"]]\n",
    "        #data_row.insert(0,label)\n",
    "        #data_row.insert(0,model_name)\n",
    "        score_type='precision'\n",
    "        data_row=[model_name,label,score_type,report[label][score_type]]\n",
    "        df=df.append(pd.Series(data_row,index=df.columns),sort=False,ignore_index=True)\n",
    "        score_type='recall'\n",
    "        data_row=[model_name,label,score_type,report[label][score_type]]\n",
    "        df=df.append(pd.Series(data_row,index=df.columns),sort=False,ignore_index=True)\n",
    "        score_type='f1-score'\n",
    "        data_row=[model_name,label,score_type,report[label][score_type]]\n",
    "        df=df.append(pd.Series(data_row,index=df.columns),sort=False,ignore_index=True)\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_train     = train_X_total[:,0:400]\n",
    "tri_train    = train_X_total[:,400:8400]\n",
    "di_sc_train  = train_X_total[:,8400:8449] \n",
    "tri_sc_train = train_X_total[:,8449:8792]\n",
    "tt_train     = train_X_total[:,8792:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_test     = test_X_total[:,0:400]\n",
    "tri_test    = test_X_total[:,400:8400]\n",
    "di_sc_test  = test_X_total[:,8400:8449] \n",
    "tri_sc_test = test_X_total[:,8449:8792]\n",
    "tt_test     = test_X_total[:,8792:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_index = test_Y.argmax(axis=1) # Convert one-hot to index\n",
    "labels_names=[\"Major capsid\",\"Minor capsid\",\"Baseplate\",\"Major tail\",\"Minor tail\",\"Portal\",\"Tail fiber\",\n",
    "             \"Tail shaft\",\"Collar\",\"Head-Tail joining\"]\n",
    "labels_dataframe=[\"Major capsid\",\"Minor capsid\",\"Baseplate\",\"Major tail\",\"Minor tail\",\"Portal\",\"Tail fiber\",\n",
    "                 \"Tail shaft\",\"Collar\",\"Head-Tail joining\",\"weighted avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=di_test\n",
    "model_name='di.h5'\n",
    "\n",
    "model = load_model( os.path.join(phage_init.model_dir,model_name) )\n",
    "test_Y_predicted = model.predict_classes(test_X)\n",
    "print(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))\n",
    "df=add_to_df(df,test_Y_index, test_Y_predicted,model_name)\n",
    "F.write(model_name)\n",
    "F.write(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=numpy.concatenate((di_test,tt_test),axis=1)\n",
    "model_name='di_p.h5'\n",
    "\n",
    "model = load_model( os.path.join(phage_init.model_dir,model_name) )\n",
    "test_Y_predicted = model.predict_classes(test_X)\n",
    "print(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))\n",
    "df=add_to_df(df,test_Y_index, test_Y_predicted,model_name)\n",
    "F.write(model_name)\n",
    "F.write(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter\n",
    "zz=Counter(test_Y_index)\n",
    "sample_w=[zz[i] for i in range(0,10,1)]\n",
    "\n",
    "CM=confusion_matrix(test_Y_index, test_Y_predicted)\n",
    "CM_n=CM/numpy.array(sample_w)[:,None]\n",
    "scale_up=1.3\n",
    "plt.figure(figsize=[6.4*scale_up, 4.8*scale_up])\n",
    "plt.imshow(CM_n, interpolation='nearest')\n",
    "plt.title('CM')\n",
    "plt.colorbar()\n",
    "tick_marks = numpy.arange(len(labels_names))\n",
    "plt.xticks(tick_marks, labels_names, rotation=90)\n",
    "plt.yticks(tick_marks, labels_names)\n",
    "fmt = '.2f'\n",
    "for i, j in itertools.product(range(CM_n.shape[0]), range(CM_n.shape[1])):\n",
    "        plt.text(j, i, format(CM_n[i, j], fmt),horizontalalignment=\"center\",verticalalignment='center',\n",
    "                color=\"white\" if CM_n[i, j] < 0.25 else \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=tri_test\n",
    "model_name='tri.h5'\n",
    "\n",
    "model = load_model( os.path.join(phage_init.model_dir,model_name) )\n",
    "test_Y_predicted = model.predict_classes(test_X)\n",
    "print(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))\n",
    "df=add_to_df(df,test_Y_index, test_Y_predicted,model_name)\n",
    "F.write(model_name)\n",
    "F.write(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=numpy.concatenate((tri_test,tt_test),axis=1)\n",
    "model_name='tri_p.h5'\n",
    "\n",
    "model = load_model( os.path.join(phage_init.model_dir,model_name) )\n",
    "test_Y_predicted = model.predict_classes(test_X)\n",
    "print(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))\n",
    "df=add_to_df(df,test_Y_index, test_Y_predicted,model_name)\n",
    "F.write(model_name)\n",
    "F.write(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=di_sc_test\n",
    "model_name='di_sc.h5'\n",
    "\n",
    "model = load_model( os.path.join(phage_init.model_dir,model_name) )\n",
    "test_Y_predicted = model.predict_classes(test_X)\n",
    "print(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))\n",
    "df=add_to_df(df,test_Y_index, test_Y_predicted,model_name)\n",
    "F.write(model_name)\n",
    "F.write(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=numpy.concatenate((di_sc_test,tt_test),axis=1)\n",
    "model_name='di_sc_p.h5'\n",
    "\n",
    "model = load_model( os.path.join(phage_init.model_dir,model_name) )\n",
    "test_Y_predicted = model.predict_classes(test_X)\n",
    "print(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))\n",
    "df=add_to_df(df,test_Y_index, test_Y_predicted,model_name)\n",
    "F.write(model_name)\n",
    "F.write(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=tri_sc_test\n",
    "model_name='tri_sc.h5'\n",
    "\n",
    "model = load_model( os.path.join(phage_init.model_dir,model_name) )\n",
    "test_Y_predicted = model.predict_classes(test_X)\n",
    "print(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))\n",
    "df=add_to_df(df,test_Y_index, test_Y_predicted,model_name)\n",
    "F.write(model_name)\n",
    "F.write(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=numpy.concatenate((tri_sc_test,tt_test),axis=1)\n",
    "model_name='tri_sc_p.h5'\n",
    "\n",
    "model = load_model( os.path.join(phage_init.model_dir,model_name) )\n",
    "test_Y_predicted = model.predict_classes(test_X)\n",
    "print(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))\n",
    "df=add_to_df(df,test_Y_index, test_Y_predicted,model_name)\n",
    "F.write(model_name)\n",
    "F.write(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=test_X_total\n",
    "model_name='all.h5'\n",
    "\n",
    "model = load_model( os.path.join(phage_init.model_dir,model_name) )\n",
    "test_Y_predicted = model.predict_classes(test_X)\n",
    "print(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))\n",
    "df=add_to_df(df,test_Y_index, test_Y_predicted,model_name)\n",
    "F.write(model_name)\n",
    "F.write(classification_report(test_Y_index, test_Y_predicted, target_names=labels_names ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df=df[df['class'] == 'weighted avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(18, 15)\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax.tick_params(axis='y',labelsize=16)\n",
    "ax.tick_params(axis='x',labelsize=14)\n",
    "ax.set_title('Weighted average model metrics', fontsize=40,va='bottom')\n",
    "sns.barplot(ax=ax,y=\"value\", x=\"model\", hue=\"score_type\", data=avg_df)\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "l = ax.legend()\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='22') # for legend text\n",
    "#print(dir(l))\n",
    "ax.set(ylim=(0, 1))\n",
    "plt.show()\n",
    "fig.savefig('avg_score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df=df[df['score_type'] == 'f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "fig2.set_size_inches(18, 15)\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax2.tick_params(axis='y',labelsize=16)\n",
    "ax2.tick_params(axis='x',labelsize=14)\n",
    "ax2.set_title('Per class model metrics', fontsize=40,va='bottom')\n",
    "sns.barplot(ax=ax2,y=\"value\", x=\"model\", hue=\"class\", data=f1_df)\n",
    "ax2.set_ylabel('')    \n",
    "ax2.set_xlabel('')\n",
    "l = ax2.legend()\n",
    "plt.setp(ax2.get_legend().get_texts(), fontsize='22') # for legend text\n",
    "#print(dir(l))\n",
    "ax2.set(ylim=(0, 1))\n",
    "ax2.set(xlim=(-0.5, 11))\n",
    "plt.show()\n",
    "fig2.savefig('f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensor_4)",
   "language": "python",
   "name": "conda_tensor_4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
