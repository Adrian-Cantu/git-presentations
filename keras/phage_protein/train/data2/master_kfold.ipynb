{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import phage_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved matrices\n",
    "import pickle\n",
    "train_X_total=pickle.load(open( os.path.join(phage_init.data_dir,\"train_x_data2_full.p\"), \"rb\" ) )\n",
    "test_X_total=pickle.load(open( os.path.join(phage_init.data_dir,\"test_x_data2_full.p\"), \"rb\" ) )\n",
    "train_Y=pickle.load(open( os.path.join(phage_init.data_dir,\"train_y_data2_full.p\"), \"rb\" ) )\n",
    "test_Y=pickle.load(open( os.path.join(phage_init.data_dir,\"test_y_data2_full.p\"), \"rb\" ) )\n",
    "mean_total=pickle.load(open( os.path.join(phage_init.data_dir,\"mean_data2_full.p\"), \"rb\" ) )\n",
    "std_total=pickle.load(open( os.path.join(phage_init.data_dir,\"std_data2_full.p\"), \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_train     = train_X_total[:,0:400]\n",
    "tri_train    = train_X_total[:,400:8400]\n",
    "di_sc_train  = train_X_total[:,8400:8449] \n",
    "tri_sc_train = train_X_total[:,8449:8792]\n",
    "tt_train     = train_X_total[:,8792:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_test     = test_X_total[:,0:400]\n",
    "tri_test    = test_X_total[:,400:8400]\n",
    "di_sc_test  = test_X_total[:,8400:8449] \n",
    "tri_sc_test = test_X_total[:,8449:8792]\n",
    "tt_test     = test_X_total[:,8792:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_di     = mean_total[0:400]\n",
    "mean_tri    = mean_total[400:8400]\n",
    "mean_di_sc  = mean_total[8400:8449] \n",
    "mean_tri_sc = mean_total[8449:8792]\n",
    "mean_tt     = mean_total[8792:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_di     = std_total[0:400]\n",
    "std_tri    = std_total[400:8400]\n",
    "std_di_sc  = std_total[8400:8449] \n",
    "std_tri_sc = std_total[8449:8792]\n",
    "std_tt     = std_total[8792:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import keras and numpy\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this list the devices, just making sure there is a GPU present, you might be fine with no GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = open(os.path.join(phage_init.model_dir,\"10_cross.log\"),'w') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formated_train(model_name):\n",
    "    train_x=[]\n",
    "    if model_name == 'di':\n",
    "        train_x=di_train\n",
    "    elif model_name == 'di_p':\n",
    "        train_x=numpy.concatenate((di_train,tt_train),axis=1)\n",
    "    elif model_name == 'tri':\n",
    "        train_x=tri_train\n",
    "    elif model_name == 'tri_p':\n",
    "        train_x=numpy.concatenate((tri_train,tt_train),axis=1)\n",
    "    elif model_name == 'di_sc':\n",
    "        train_x=di_sc_train\n",
    "    elif model_name == 'di_sc_p':\n",
    "        train_x=numpy.concatenate((di_sc_train,tt_train),axis=1)\n",
    "    elif model_name == 'tri_sc':\n",
    "        train_x=tri_sc_train\n",
    "    elif model_name == 'tri_sc_p':\n",
    "        train_x=numpy.concatenate((tri_sc_train,tt_train),axis=1)\n",
    "    elif model_name == 'all':\n",
    "        train_x=train_X_total\n",
    "    return train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def train_kfold(model_name):\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=43)\n",
    "    train_Y_index = train_Y.argmax(axis=1)\n",
    "    cvscores = []\n",
    "    model_number=1\n",
    "    train_X=get_formated_train(model_name=model_name)\n",
    "    f_num=train_X.shape[1]\n",
    "    print(\"Doing cross validation on \"+model_name)\n",
    "    F.write(\"Doing cross validation on \"+model_name)\n",
    "    for train, test in kfold.split(train_X, train_Y_index):\n",
    "    #model with 2 leyers of 100 LSTM neurons\n",
    "        train_YY = numpy.eye(10)[train_Y_index[train]]\n",
    "        test_YY  = numpy.eye(10)[train_Y_index[test]]\n",
    "        model = Sequential()\n",
    "        opt=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        model.add(Dense(f_num, input_dim=f_num, kernel_initializer='random_uniform',activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(200,activation='relu'))\n",
    "    #model.add(Dense(200,activation='sigmoid'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(200,activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(10,activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        model.fit(train_X[train], train_YY, epochs=30, batch_size=3000, verbose=0)\n",
    "        scores = model.evaluate(train_X[test], test_YY, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        F.write(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        model.save( os.path.join(phage_init.model_dir,model_name+'_'+\"{:02d}\".format(model_number)+'.h5') )\n",
    "        pickle.dump(train_X[test], open( os.path.join(phage_init.data_dir, model_name+'_'+\"{:02d}\".format(model_number)+'_test_X.p' ), \"wb\"))\n",
    "        pickle.dump(test_YY, open( os.path.join(phage_init.data_dir, model_name+'_'+\"{:02d}\".format(model_number)+'_test_Y.p' ), \"wb\"))\n",
    "        model_number=model_number+1\n",
    "        del model\n",
    "        F.flush()\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))  \n",
    "    F.write(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n",
    "    F.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing cross validation on di\n",
      "acc: 91.29%\n",
      "acc: 91.05%\n",
      "acc: 91.20%\n",
      "acc: 91.38%\n",
      "acc: 91.30%\n",
      "acc: 91.30%\n",
      "acc: 89.84%\n",
      "acc: 89.31%\n",
      "acc: 89.59%\n",
      "acc: 88.91%\n",
      "90.52% (+/- 0.93%)\n",
      "Doing cross validation on di_p\n",
      "acc: 91.67%\n",
      "acc: 91.39%\n",
      "acc: 91.88%\n",
      "acc: 91.74%\n",
      "acc: 91.20%\n",
      "acc: 91.84%\n",
      "acc: 91.52%\n",
      "acc: 90.47%\n",
      "acc: 90.27%\n",
      "acc: 90.63%\n",
      "91.26% (+/- 0.57%)\n",
      "Doing cross validation on tri\n",
      "acc: 92.73%\n"
     ]
    }
   ],
   "source": [
    "all_models=['di','di_p','tri','tri_p','di_sc','di_sc_p','tri_sc','tri_sc_p','all']\n",
    "for this_model in all_models:\n",
    "    train_kfold(this_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensor_4)",
   "language": "python",
   "name": "conda_tensor_4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
