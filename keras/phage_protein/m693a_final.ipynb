{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved matrices\n",
    "import pickle\n",
    "train_X=pickle.load(open( \"dipep_new_train_x.p\", \"rb\" ) )\n",
    "test_X=pickle.load(open( \"dipep_new_test_x.p\", \"rb\" ) )\n",
    "train_Y=pickle.load(open( \"dipep_new_train_y.p\", \"rb\" ) )\n",
    "test_Y=pickle.load(open( \"dipep_new_test_y.p\", \"rb\" ) )\n",
    "mean_arr=pickle.load(open( \"dipep_new_mean.p\", \"rb\" ) )\n",
    "mean_std=pickle.load(open( \"dipep_new_std.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import keras and numpy\n",
    "import numpy\n",
    "from scipy import linalg as LA\n",
    "from scipy.optimize import fminbound as OPT\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9320286971556097022\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15595618304\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11076868877381831054\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#this list the devices, just making sure there is a GPU present, you might be fine with no GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "f1=open('./testfile', 'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_f(lr=0.001, dd1=0.2, dd2=0.2, dd3=0.2, vv=0):\n",
    "    #opt=Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    opt=SGD(lr=lr, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(402, input_dim=402, kernel_initializer='random_uniform',activation='relu'))\n",
    "    model.add(Dropout(dd1))\n",
    "    model.add(Dense(200,activation='relu'))\n",
    "    model.add(Dropout(dd2))\n",
    "    model.add(Dense(200,activation='relu'))\n",
    "    model.add(Dropout(dd3))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    hist=model.fit(train_X, train_Y,verbose=vv, epochs=50, batch_size=200)\n",
    "    #scores = model.evaluate(test_X, test_Y, verbose=vv)\n",
    "    arr_pred=model.predict(test_X)\n",
    "    #if vv:\n",
    "    #    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    keras.backend.clear_session()\n",
    "    return LA.norm(arr_pred-test_Y)\n",
    "    #return scores[1]\n",
    "    #return hist;\n",
    "    \n",
    "def evaluate_f_v(VV):\n",
    "    val=evaluate_f(lr=VV[0], dd1=VV[1], dd2=VV[2], dd3=VV[3], vv=0)\n",
    "    return val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_f_acc(lr=0.001, dd1=0.2, dd2=0.2, dd3=0.2, vv=0):\n",
    "    #opt=Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    opt=SGD(lr=lr, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(402, input_dim=402, kernel_initializer='random_uniform',activation='relu'))\n",
    "    model.add(Dropout(dd1))\n",
    "    model.add(Dense(200,activation='relu'))\n",
    "    model.add(Dropout(dd2))\n",
    "    model.add(Dense(200,activation='relu'))\n",
    "    model.add(Dropout(dd3))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    hist=model.fit(train_X, train_Y,verbose=vv, epochs=50, batch_size=200)\n",
    "    scores = model.evaluate(test_X, test_Y, verbose=vv)\n",
    "    #arr_pred=model.predict(test_X)\n",
    "    #if vv:\n",
    "    #    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    keras.backend.clear_session()\n",
    "    #return LA.norm(arr_pred-test_Y)\n",
    "    return scores[1]\n",
    "    #return hist;\n",
    "    \n",
    "def evaluate_f_acc_v(VV):\n",
    "    val=evaluate_f_acc(lr=VV[0], dd1=VV[1], dd2=VV[2], dd3=VV[3], vv=0)\n",
    "    return val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_evaluate_f(lr=0.001, dd1=0.2, dd2=0.2, dd3=0.2, vv=0):\n",
    "    f1=evaluate_f(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    f2=evaluate_f(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    f3=evaluate_f(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    f4=evaluate_f(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    f5=evaluate_f(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    return numpy.average([f1,f2,f3,f4,f5])\n",
    "\n",
    "def avg_evaluate_f_v(VV):\n",
    "    val=avg_evaluate_f(lr=VV[0], dd1=VV[1], dd2=VV[2], dd3=VV[3], vv=0)\n",
    "    return val\n",
    "\n",
    "def avg_evaluate_f_acc(lr=0.001, dd1=0.2, dd2=0.2, dd3=0.2, vv=0):\n",
    "    f1=evaluate_f_acc(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    f2=evaluate_f_acc(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    f3=evaluate_f_acc(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    f4=evaluate_f_acc(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    f5=evaluate_f_acc(lr=lr, dd1=dd1, dd2=dd3, dd3=dd3, vv=vv)\n",
    "    return numpy.average([f1,f2,f3,f4,f5])\n",
    "\n",
    "def avg_evaluate_f_acc_v(VV):\n",
    "    val=avg_evaluate_f_acc(lr=VV[0], dd1=VV[1], dd2=VV[2], dd3=VV[3], vv=0)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_G(lr=0.001, dd1=0.2, dd2=0.2, dd3=0.2,h=0.001, k=0.0001):\n",
    "    df_lr=((avg_evaluate_f(lr=lr+k,dd1=dd1, dd2=dd2, dd3=dd3, vv=0)-\n",
    "            avg_evaluate_f(lr=lr-k,dd1=dd1, dd2=dd2, dd3=dd3, vv=0))/(2*k))\n",
    "    df_dd1=((avg_evaluate_f(dd1=dd1+h,dd2=dd2, dd3=dd3, vv=0,lr=lr)-\n",
    "             avg_evaluate_f(dd1=dd1-h,dd2=dd2, dd3=dd3, vv=0,lr=lr))/(2*h))\n",
    "    df_dd2=((avg_evaluate_f(dd2=dd2+h,dd1=dd1, dd3=dd3, vv=0,lr=lr)-\n",
    "             avg_evaluate_f(dd2=dd2-h,dd1=dd1, dd3=dd3, vv=0,lr=lr))/(2*h))\n",
    "    df_dd3=((avg_evaluate_f(dd3=dd3+h,dd1=dd1, dd2=dd2, vv=0,lr=lr)-\n",
    "             avg_evaluate_f(dd3=dd3-h,dd1=dd1, dd2=dd2, vv=0,lr=lr))/(2*h))\n",
    "    G=numpy.array([df_lr,df_dd1,df_dd2,df_dd3],dtype=numpy.float)\n",
    "    return G\n",
    "\n",
    "def evaluate_G_v(VV):\n",
    "    val=evaluate_G(lr=VV[0], dd1=VV[1], dd2=VV[2], dd3=VV[3])\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_H(ff,lr=0.001, dd1=0.2, dd2=0.2, dd3=0.2,h=0.001, k=0.0001,vv=0):\n",
    "    \n",
    "    df_lr_lr=((avg_evaluate_f(lr=lr+2*k, dd1=dd1, dd2=dd2, dd3=dd3,vv=vv)-2*ff+\n",
    "               avg_evaluate_f(lr=lr-2*k, dd1=dd1, dd2=dd2, dd3=dd3,vv=vv))/(4*k*k))\n",
    "    df_dd1_dd1=((avg_evaluate_f(lr=lr, dd1=dd1+2*h, dd2=dd2, dd3=dd3,vv=vv)-2*ff+\n",
    "               avg_evaluate_f(lr=lr, dd1=dd1-2*h, dd2=dd2, dd3=dd3,vv=vv))/(4*h*h))\n",
    "    df_dd2_dd2=((avg_evaluate_f(lr=lr, dd1=dd1, dd2=dd2+2*h, dd3=dd3,vv=vv)-2*ff+\n",
    "               avg_evaluate_f(lr=lr, dd1=dd1, dd2=dd2-2*h, dd3=dd3,vv=vv))/(4*h*h))\n",
    "    df_dd3_dd3=((avg_evaluate_f(lr=lr, dd1=dd1, dd2=dd2, dd3=dd3+2*h,vv=vv)-2*ff+\n",
    "               avg_evaluate_f(lr=lr, dd1=dd1, dd2=dd2, dd3=dd3-2*h,vv=vv))/(4*h*h))\n",
    "    \n",
    "    df_lr_dd1=((avg_evaluate_f(lr=lr+k, dd1=dd1+h, dd2=dd2, dd3=dd3,vv=vv)-\n",
    "                avg_evaluate_f(lr=lr+k, dd1=dd1-h, dd2=dd2, dd3=dd3,vv=vv)-\n",
    "                avg_evaluate_f(lr=lr-k, dd1=dd1+h, dd2=dd2, dd3=dd3,vv=vv)+\n",
    "                avg_evaluate_f(lr=lr-k, dd1=dd1-h, dd2=dd2, dd3=dd3,vv=vv))/(4*k*h))\n",
    "    df_lr_dd2=((avg_evaluate_f(lr=lr+k, dd1=dd1, dd2=dd2+h, dd3=dd3,vv=vv)-\n",
    "                avg_evaluate_f(lr=lr+k, dd1=dd1, dd2=dd2-h, dd3=dd3,vv=vv)-\n",
    "                avg_evaluate_f(lr=lr-k, dd1=dd1, dd2=dd2+h, dd3=dd3,vv=vv)+\n",
    "                avg_evaluate_f(lr=lr-k, dd1=dd1, dd2=dd2-h, dd3=dd3,vv=vv))/(4*k*h))\n",
    "    df_lr_dd3=((avg_evaluate_f(lr=lr+k, dd1=dd1, dd2=dd2, dd3=dd3+h,vv=vv)-\n",
    "                avg_evaluate_f(lr=lr+k, dd1=dd1, dd2=dd2, dd3=dd3-h,vv=vv)-\n",
    "                avg_evaluate_f(lr=lr-k, dd1=dd1, dd2=dd2, dd3=dd3+h,vv=vv)+\n",
    "                avg_evaluate_f(lr=lr-k, dd1=dd1, dd2=dd2, dd3=dd3-h,vv=vv))/(4*k*h))\n",
    "    \n",
    "    df_dd1_dd2=((avg_evaluate_f(lr=lr, dd1=dd1+h, dd2=dd2+h, dd3=dd3,vv=vv)-\n",
    "                 avg_evaluate_f(lr=lr, dd1=dd1+h, dd2=dd2-h, dd3=dd3,vv=vv)-\n",
    "                 avg_evaluate_f(lr=lr, dd1=dd1-h, dd2=dd2+h, dd3=dd3,vv=vv)+\n",
    "                 avg_evaluate_f(lr=lr, dd1=dd1-h, dd2=dd2-h, dd3=dd3,vv=vv))/(4*h*h))\n",
    "    df_dd1_dd3=((avg_evaluate_f(lr=lr, dd1=dd1+h, dd2=dd2, dd3=dd3+h,vv=vv)-\n",
    "                 avg_evaluate_f(lr=lr, dd1=dd1+h, dd2=dd2, dd3=dd3-h,vv=vv)-\n",
    "                 avg_evaluate_f(lr=lr, dd1=dd1-h, dd2=dd2, dd3=dd3+h,vv=vv)+\n",
    "                 avg_evaluate_f(lr=lr, dd1=dd1-h, dd2=dd2, dd3=dd3-h,vv=vv))/(4*h*h))\n",
    "    \n",
    "    df_dd2_dd3=((avg_evaluate_f(lr=lr, dd1=dd1, dd2=dd2+h, dd3=dd3+h,vv=vv)-\n",
    "                 avg_evaluate_f(lr=lr, dd1=dd1, dd2=dd2+h, dd3=dd3-h,vv=vv)-\n",
    "                 avg_evaluate_f(lr=lr, dd1=dd1, dd2=dd2-h, dd3=dd3+h,vv=vv)+\n",
    "                 avg_evaluate_f(lr=lr, dd1=dd1, dd2=dd2-h, dd3=dd3-h,vv=vv))/(4*h*h))\n",
    "    \n",
    "    \n",
    "    H=numpy.array([[df_lr_lr ,df_lr_dd1 ,df_lr_dd2 ,df_lr_dd3],\n",
    "                   [df_lr_dd1,df_dd1_dd1,df_dd1_dd2,df_dd1_dd3],\n",
    "                   [df_lr_dd2,df_dd1_dd2,df_dd2_dd2,df_dd2_dd3],\n",
    "                   [df_lr_dd3,df_dd1_dd3,df_dd2_dd3,df_dd3_dd3]],dtype=numpy.float)\n",
    "    #HH=numpy.reshape(H,(4,4))\n",
    "\n",
    "    return H\n",
    "\n",
    "def evaluate_H_v(ff,VV):\n",
    "    val=evaluate_H(ff,lr=VV[0], dd1=VV[1], dd2=VV[2], dd3=VV[3], vv=0)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_model(pp,ff,GG,HH):\n",
    "    RR=ff+pp@GG +(0.5*(pp@HH@pp))\n",
    "    return RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_vec(mu,stp_dir,full_step):\n",
    "    return mu[0]*stp_dir+mu[1]*full_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_sub_space(stp,fu,HH,GG):\n",
    "    A=numpy.array([[stp @ HH @ stp, stp @ HH @ fu],\n",
    "                   [fu  @ HH @ stp, fu  @ HH @ fu]],dtype=numpy.float)\n",
    "    b=numpy.array([stp @GG ,fu @ GG],dtype=numpy.float)\n",
    "    return -1*numpy.linalg.solve(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_search(sigma,vec1,vec2,ff,GG,HH,rad):\n",
    "    kk=rad*(numpy.cos(sigma)*vec1+numpy.sin(sigma)*vec2)\n",
    "    return q_model(kk,ff,GG,HH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vec(sigma,vec1,vec2,rad):\n",
    "    kk=rad*(numpy.cos(sigma)*vec1+numpy.sin(sigma)*vec2)\n",
    "    return kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_base(stp,fu):\n",
    "    q1=stp/LA.norm(stp)\n",
    "    inn=fu-numpy.inner(stp,fu)*q1\n",
    "    q2=inn/LA.norm(inn)\n",
    "    \n",
    "    return (q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(beta,A):\n",
    "    I=numpy.identity(4)\n",
    "    HH=A+beta*I\n",
    "    return numpy.linalg.cond(HH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2321\u001b[0;31m         \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2322\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'dense_2/MatMul' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2324\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2326\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'dense_2/MatMul' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c07649150fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluating gradient'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mGG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_G_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mpath_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1535ca771ecc>\u001b[0m in \u001b[0;36mevaluate_G_v\u001b[0;34m(VV)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_G_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1535ca771ecc>\u001b[0m in \u001b[0;36mevaluate_G\u001b[0;34m(lr, dd1, dd2, dd3, h, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     df_lr=((avg_evaluate_f(lr=lr+k,dd1=dd1, dd2=dd2, dd3=dd3, vv=0)-\n\u001b[0m\u001b[1;32m      3\u001b[0m             avg_evaluate_f(lr=lr-k,dd1=dd1, dd2=dd2, dd3=dd3, vv=0))/(2*k))\n\u001b[1;32m      4\u001b[0m     df_dd1=((avg_evaluate_f(dd1=dd1+h,dd2=dd2, dd3=dd3, vv=0,lr=lr)-\n\u001b[1;32m      5\u001b[0m              avg_evaluate_f(dd1=dd1-h,dd2=dd2, dd3=dd3, vv=0,lr=lr))/(2*h))\n",
      "\u001b[0;32m<ipython-input-5-901b2ac42ed1>\u001b[0m in \u001b[0;36mavg_evaluate_f\u001b[0;34m(lr, dd1, dd2, dd3, vv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mavg_evaluate_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mf3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-28a0726ac94f>\u001b[0m in \u001b[0;36mevaluate_f\u001b[0;34m(lr, dd1, dd2, dd3, vv)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mhist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#scores = model.evaluate(test_X, test_Y, verbose=vv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0marr_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    508\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    510\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    511\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m     \"\"\"\n\u001b[0;32m-> 2757\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m--> 596\u001b[0;31m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 776\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    777\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    396\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 776\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    777\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1095\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4558\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4559\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4560\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4561\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4562\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3190\u001b[0m   \u001b[0;31m# Helper functions to create operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3191\u001b[0;31m   @deprecated_args(None,\n\u001b[0m\u001b[1;32m   3192\u001b[0m                    \u001b[0;34m\"Shapes are always computed; don't use the compute_shapes \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                    \"as it has no effect.\", \"compute_shapes\")\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = numpy.empty((0,4), dtype=numpy.float)\n",
    "path_grad=numpy.empty((0,4), dtype=numpy.float)\n",
    "zero_arr=numpy.array([0,0,0,0])\n",
    "rad=0.001\n",
    "max_rad=0.1\n",
    "tol=1/4\n",
    "GG=1\n",
    "XX=numpy.array([0.001,0.2,0.2,0.2])\n",
    "tt=1\n",
    "rho_count=0\n",
    "#cat_n.reshape((1,cat_n.shape[0]))\n",
    "path = numpy.append(path,XX.reshape((1,XX.shape[0])) , axis=0)\n",
    "while ((LA.norm(GG)>0.0001) and (tt<40)):\n",
    "    print('itt= ',tt,file=f1)\n",
    "    print('evaluating function',file=f1)\n",
    "    FF=avg_evaluate_f_v(XX)\n",
    "    print('done ',FF,file=f1)\n",
    "    print('evaluating gradient',file=f1)\n",
    "    GG=evaluate_G_v(XX)\n",
    "    path_grad=numpy.append(path_grad,GG.reshape((1,GG.shape[0])) , axis=0)\n",
    "    if(LA.norm(GG)<0.0001):\n",
    "        break\n",
    "    print('evaluating hessian',file=f1)\n",
    "    HH=evaluate_H_v(FF,XX)\n",
    "    print('done',file=f1)\n",
    "    print('getting eigenvalues',file=f1)\n",
    "    min_e=numpy.real(numpy.min(LA.eigvals(HH)))\n",
    "    \n",
    "    print('min eig =',  min_e,file=f1)\n",
    "    if min_e < 0:\n",
    "        (kk1,kk2,kk3,kk4)=OPT(condition,-1.1*min_e,-2*min_e,args=(HH,),full_output=1)\n",
    "        print(kk1,kk2,kk3,kk4)\n",
    "        print(kk1/min_e)\n",
    "        HH=HH+kk1*numpy.identity(4)\n",
    "    print('solving subspace',file=f1)\n",
    "    full_step=-1*numpy.linalg.solve(HH,GG)\n",
    "    stp_dir=-1*((GG @ GG)/(GG @ HH @ GG))*GG\n",
    "    kk=solve_sub_space(stp_dir,full_step,HH,GG)\n",
    "    pp=sub_vec(kk,stp_dir,full_step)\n",
    "    t_pp=XX+pp\n",
    "    (q1,q2)=change_base(stp_dir,full_step)\n",
    "    if ((LA.norm(pp)>rad) or (numpy.min(t_pp)<0) or (numpy.max(t_pp[1:])>1)):\n",
    "        dic= (q1,q2,FF,GG,HH,rad)\n",
    "        (opt1,opt2,opt3,opt4)=OPT(one_search,0,2*numpy.pi,args=dic,full_output=1)\n",
    "        pp=one_vec(opt1,q1,q2,rad)\n",
    "    FF_n=avg_evaluate_f_v(XX+pp)\n",
    "    rho_top=FF-FF_n\n",
    "    rho_bot=q_model(zero_arr,FF,GG,HH)-q_model(pp,FF,GG,HH)\n",
    "    if (rho_bot<10*numpy.finfo(float).eps):\n",
    "        print('rho_bot too close to epsilon',file=f1)\n",
    "        rad=0.001\n",
    "        rho_count=rho_count+1\n",
    "        continue\n",
    "    rho=rho_top/rho_bot\n",
    "    while ((rho < 1/4) or (LA.norm(pp)>rad) or (numpy.min(t_pp)<0) or (numpy.max(t_pp[1:])>1)):\n",
    "        rad=rad*1/4\n",
    "        dic= (q1,q2,FF,GG,HH,rad)\n",
    "        (opt1,opt2,opt3,opt4)=OPT(one_search,0,2*numpy.pi,args=dic,full_output=1)\n",
    "        pp=one_vec(kk1,q1,q2,rad)\n",
    "        FF_n=avg_evaluate_f_v(XX+pp)\n",
    "        rho_top=FF-FF_n\n",
    "        rho_bot=q_model(zero_arr,FF,GG,HH)-q_model(pp,FF,GG,HH)\n",
    "        if (rho_bot<10*numpy.finfo(float).eps):\n",
    "            print('rho_bot too close to epsilon',file=f1)\n",
    "            rad=0.001\n",
    "            rho_count=rho_count+1\n",
    "            break\n",
    "        rho=rho_top/rho_bot\n",
    "    if ((rho>3/4) and (LA.norm(pp)<1.001*rad)):\n",
    "        rad=min(2*rad,max_rad)\n",
    "    XX=XX+pp\n",
    "    tt=tt+1\n",
    "    print('final radius ',rad,file=f1)\n",
    "    print('grad norm ',LA.norm(GG),file=f1)\n",
    "    path = numpy.append(path,XX.reshape((1,XX.shape[0])) , axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path)\n",
    "print(path_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(path, open( \"path.p\", \"wb\" ) )\n",
    "pickle.dump(path_grad, open( \"path_grad.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX2=numpy.array([0.001,0.2,0.2,0.2])\n",
    "#GG_i=GG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 18s, sys: 8.42 s, total: 3min 27s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FF=avg_evaluate_f_v(XX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 34s, sys: 1min 12s, total: 27min 46s\n",
      "Wall time: 13min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GG_i=evaluate_G_v(XX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 50min 49s, sys: 5min 2s, total: 1h 55min 51s\n",
      "Wall time: 56min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "HH=evaluate_H_v(FF,XX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model = load_model('di_new_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_pred=model.predict(test_X)\n",
    "#numpy.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(arr_pred-test_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX=pickle.load(open( \"2_path.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001 0.2   0.2   0.2  ]  ->  0.5819259260053988\n",
      "[0.00669244 0.19995767 0.20278899 0.1964307 ]  ->  0.8011851851851851\n"
     ]
    }
   ],
   "source": [
    "print(XX[0,...],' -> ',avg_evaluate_f_acc_v(XX[0,...]))\n",
    "print(XX[29,...],' -> ',avg_evaluate_f_acc_v(XX[29,...]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
