{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved matrices\n",
    "import pickle\n",
    "train_X=pickle.load(open( \"tri_train_x.p\", \"rb\" ) )\n",
    "test_X=pickle.load(open( \"tri_test_x.p\", \"rb\" ) )\n",
    "train_Y=pickle.load(open( \"tri_train_y.p\", \"rb\" ) )\n",
    "test_Y=pickle.load(open( \"tri_test_y.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import keras and numpy\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2227119070761305980\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15595618304\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16590985881218773785\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#this list the devices, just making sure there is a GPU present, you might be fine with no GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 8000)              64008000  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                80010     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 64,088,440\n",
      "Trainable params: 64,088,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model with 2 leyers of 100 LSTM neurons\n",
    "model = Sequential()\n",
    "model.add(Dense(8000, input_dim=8000, kernel_initializer='random_uniform',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(LSTM(100))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "24000/24000 [==============================] - 4s 179us/step - loss: 2.1715 - acc: 0.1965\n",
      "Epoch 2/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 1.8650 - acc: 0.3024\n",
      "Epoch 3/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 1.6012 - acc: 0.4090\n",
      "Epoch 4/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 1.3486 - acc: 0.5015\n",
      "Epoch 5/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 1.1578 - acc: 0.5751\n",
      "Epoch 6/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 1.0234 - acc: 0.6274\n",
      "Epoch 7/80\n",
      "24000/24000 [==============================] - 2s 92us/step - loss: 0.9455 - acc: 0.6569\n",
      "Epoch 8/80\n",
      "24000/24000 [==============================] - 2s 91us/step - loss: 0.8914 - acc: 0.6798\n",
      "Epoch 9/80\n",
      "24000/24000 [==============================] - 2s 88us/step - loss: 0.8392 - acc: 0.7019\n",
      "Epoch 10/80\n",
      "24000/24000 [==============================] - 2s 93us/step - loss: 0.7893 - acc: 0.7199\n",
      "Epoch 11/80\n",
      "24000/24000 [==============================] - 2s 99us/step - loss: 0.7636 - acc: 0.7311\n",
      "Epoch 12/80\n",
      "24000/24000 [==============================] - 2s 99us/step - loss: 0.7263 - acc: 0.7424\n",
      "Epoch 13/80\n",
      "24000/24000 [==============================] - 2s 100us/step - loss: 0.7034 - acc: 0.7505\n",
      "Epoch 14/80\n",
      "24000/24000 [==============================] - 2s 98us/step - loss: 0.6713 - acc: 0.7614\n",
      "Epoch 15/80\n",
      "24000/24000 [==============================] - 2s 94us/step - loss: 0.6595 - acc: 0.7682\n",
      "Epoch 16/80\n",
      "24000/24000 [==============================] - 2s 89us/step - loss: 0.6377 - acc: 0.7739\n",
      "Epoch 17/80\n",
      "24000/24000 [==============================] - 2s 87us/step - loss: 0.6185 - acc: 0.7796\n",
      "Epoch 18/80\n",
      "24000/24000 [==============================] - 2s 83us/step - loss: 0.6016 - acc: 0.7866\n",
      "Epoch 19/80\n",
      "24000/24000 [==============================] - 2s 84us/step - loss: 0.5970 - acc: 0.7891\n",
      "Epoch 20/80\n",
      "24000/24000 [==============================] - 2s 89us/step - loss: 0.5939 - acc: 0.7875\n",
      "Epoch 21/80\n",
      "24000/24000 [==============================] - 2s 88us/step - loss: 0.5844 - acc: 0.7904\n",
      "Epoch 22/80\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 0.5793 - acc: 0.7920\n",
      "Epoch 23/80\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 0.5638 - acc: 0.7943\n",
      "Epoch 24/80\n",
      "24000/24000 [==============================] - 2s 85us/step - loss: 0.5526 - acc: 0.7971\n",
      "Epoch 25/80\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 0.5437 - acc: 0.8013\n",
      "Epoch 26/80\n",
      "24000/24000 [==============================] - 2s 88us/step - loss: 0.5314 - acc: 0.8056\n",
      "Epoch 27/80\n",
      "24000/24000 [==============================] - 2s 85us/step - loss: 0.5342 - acc: 0.8060\n",
      "Epoch 28/80\n",
      "24000/24000 [==============================] - 2s 84us/step - loss: 0.5218 - acc: 0.8110\n",
      "Epoch 29/80\n",
      "24000/24000 [==============================] - 2s 82us/step - loss: 0.5204 - acc: 0.8113\n",
      "Epoch 30/80\n",
      "24000/24000 [==============================] - 2s 82us/step - loss: 0.5224 - acc: 0.8095\n",
      "Epoch 31/80\n",
      "24000/24000 [==============================] - 2s 82us/step - loss: 0.5032 - acc: 0.8155\n",
      "Epoch 32/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.5038 - acc: 0.8154\n",
      "Epoch 33/80\n",
      "24000/24000 [==============================] - 2s 82us/step - loss: 0.5031 - acc: 0.8163\n",
      "Epoch 34/80\n",
      "24000/24000 [==============================] - 2s 84us/step - loss: 0.4940 - acc: 0.8172\n",
      "Epoch 35/80\n",
      "24000/24000 [==============================] - 2s 83us/step - loss: 0.4948 - acc: 0.8171\n",
      "Epoch 36/80\n",
      "24000/24000 [==============================] - 2s 81us/step - loss: 0.4891 - acc: 0.8214\n",
      "Epoch 37/80\n",
      "24000/24000 [==============================] - 2s 80us/step - loss: 0.4855 - acc: 0.8207\n",
      "Epoch 38/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4789 - acc: 0.8252\n",
      "Epoch 39/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 0.4737 - acc: 0.8279\n",
      "Epoch 40/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4715 - acc: 0.8253\n",
      "Epoch 41/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4684 - acc: 0.8303\n",
      "Epoch 42/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4614 - acc: 0.8290\n",
      "Epoch 43/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 0.4627 - acc: 0.8312\n",
      "Epoch 44/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4574 - acc: 0.8314\n",
      "Epoch 45/80\n",
      "24000/24000 [==============================] - 2s 83us/step - loss: 0.4464 - acc: 0.8357\n",
      "Epoch 46/80\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 0.4536 - acc: 0.8346\n",
      "Epoch 47/80\n",
      "24000/24000 [==============================] - 2s 86us/step - loss: 0.4561 - acc: 0.8352\n",
      "Epoch 48/80\n",
      "24000/24000 [==============================] - 2s 83us/step - loss: 0.4408 - acc: 0.8385\n",
      "Epoch 49/80\n",
      "24000/24000 [==============================] - 2s 80us/step - loss: 0.4345 - acc: 0.8416\n",
      "Epoch 50/80\n",
      "24000/24000 [==============================] - 2s 80us/step - loss: 0.4322 - acc: 0.8406\n",
      "Epoch 51/80\n",
      "24000/24000 [==============================] - 2s 80us/step - loss: 0.4335 - acc: 0.8385\n",
      "Epoch 52/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 0.4313 - acc: 0.8425\n",
      "Epoch 53/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4319 - acc: 0.8408\n",
      "Epoch 54/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4312 - acc: 0.8434\n",
      "Epoch 55/80\n",
      "24000/24000 [==============================] - 2s 81us/step - loss: 0.4194 - acc: 0.8460\n",
      "Epoch 56/80\n",
      "24000/24000 [==============================] - 2s 81us/step - loss: 0.4207 - acc: 0.8445\n",
      "Epoch 57/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4179 - acc: 0.8457\n",
      "Epoch 58/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 0.4155 - acc: 0.8457\n",
      "Epoch 59/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 0.4158 - acc: 0.8468\n",
      "Epoch 60/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 0.4156 - acc: 0.8468\n",
      "Epoch 61/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 0.4090 - acc: 0.8485\n",
      "Epoch 62/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4142 - acc: 0.8463\n",
      "Epoch 63/80\n",
      "24000/24000 [==============================] - 2s 79us/step - loss: 0.4014 - acc: 0.8493\n",
      "Epoch 64/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 0.3974 - acc: 0.8515\n",
      "Epoch 65/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3918 - acc: 0.8506\n",
      "Epoch 66/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.4003 - acc: 0.8496\n",
      "Epoch 67/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3964 - acc: 0.8493\n",
      "Epoch 68/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3890 - acc: 0.8555\n",
      "Epoch 69/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3949 - acc: 0.8523\n",
      "Epoch 70/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.4007 - acc: 0.8507\n",
      "Epoch 71/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3872 - acc: 0.8545\n",
      "Epoch 72/80\n",
      "24000/24000 [==============================] - 2s 78us/step - loss: 0.3901 - acc: 0.8540\n",
      "Epoch 73/80\n",
      "24000/24000 [==============================] - 2s 80us/step - loss: 0.3905 - acc: 0.8536\n",
      "Epoch 74/80\n",
      "24000/24000 [==============================] - 2s 80us/step - loss: 0.3800 - acc: 0.8575\n",
      "Epoch 75/80\n",
      "24000/24000 [==============================] - 2s 80us/step - loss: 0.3804 - acc: 0.8562\n",
      "Epoch 76/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3843 - acc: 0.8554\n",
      "Epoch 77/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3836 - acc: 0.8586\n",
      "Epoch 78/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3807 - acc: 0.8583\n",
      "Epoch 79/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3768 - acc: 0.8590\n",
      "Epoch 80/80\n",
      "24000/24000 [==============================] - 2s 77us/step - loss: 0.3752 - acc: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2f011dcf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=80, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1675/1675 [==============================] - 0s 108us/step\n",
      "Accuracy: 75.40%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_X, test_Y, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can save the as a file so you dont have to train it every time\n",
    "model.save('my_model_tri.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jup)",
   "language": "python",
   "name": "conda_jup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
